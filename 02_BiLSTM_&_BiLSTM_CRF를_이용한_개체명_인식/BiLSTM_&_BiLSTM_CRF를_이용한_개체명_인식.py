# -*- coding: utf-8 -*-
"""BiLSTM & BiLSTM-CRF를 이용한 개체명 인식.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j9Yek2EPYvSNhK1J_WcRGAiQ0wOx5fNQ

# BiLSTM을 이용한 개체명 인식(Named Entity Recognition, NER)
양방향 LSTM을 이용하여 개체명 인식기를 만든 후에 F1-score를 사용하여 모델을 평가합니다.

## 1. 개체명 인식 데이터에 대한 이해와 전처리

앞서 사용한 데이터와는 다른 데이터를 사용하여 개체명 인식을 수행해보겠습니다. 데이터는 아래의 링크에서 다운로드합니다.

링크 : https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus
"""

import urllib.request
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

urllib.request.urlretrieve("https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/12.%20RNN%20Sequence%20Labeling/dataset/ner_dataset.csv", filename="ner_dataset.csv")
data = pd.read_csv("ner_dataset.csv", encoding="latin1")

data[:5]

"""데이터의 형식을 이해해봅시다. 

- 첫번째 열 'Sentence :#'은 다음과 같은 패턴을 가지고 있습니다. 
    - Sentence: 1이 등장하고 Null 값이 이어지다가 다시 Sentence: 2가 등장하고 다시 Null 값이 이어지다가 Sentence: 3이 등장하고 다시 Null 값이 이어지다가를 반복합니다. 
- 사실 이는 하나의 문장을 여러 행으로 나눠놓은 것입니다. 
    - 숫자값을 t라고 합시다. 
    - 첫번째 Sentence: t부터 Null 값이 나오다가 Sentence: t+1이 나오기 전까지의 모든 행은 기존에 하나의 문장이었습니다. 
    - t번째 문장을 단어 토큰화 후 각 행으로 나눠놓은 데이터이기 때문입니다. 뒤에서 Pandas의 `fillna`를 통해 하나로 묶는 작업을 해줍니다.
"""

print('데이터프레임 행의 개수 : {}'.format(len(data)))

"""현재 data의 행의 개수는 1,048,575개입니다. 하지만 뒤에서 문장 1개를 다수의 행들으로 나누어 놓은 것을 다시 1개의 행으로 병합하는 작업을 해야하기 때문에 최종 샘플의 개수는 이보다 줄어들게 됩니다. 결측값 유무를 살펴봅시다."""

print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))

"""Sentence #열에 Null 값들이 존재하고 있어 `isnull().values.any()`를 수행하였을 때 `True`가 나옵니다. `isnull().sum()`을 수행하면 각 열마다의 Null 값의 개수를 보여줍니다."""

print('어떤 열에 Null값이 있는지 출력')
print('==============================')
data.isnull().sum()

"""다른 열은 0개인데 오직 Sentences #열에서만 1,000,616개가 나온 것을 볼 수 있습니다. 전체 데이터에서 중복을 허용하지 않고 유일한 값의 개수를 셀 수 있게 해주는 `nunique()`를 사용해봅시다."""

print('sentence # 열의 중복을 제거한 값의 개수 : {}'.format(data['Sentence #'].nunique()))
print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))
print('Tag 열의 중복을 제거한 값의 개수 : {}'.format(data.Tag.nunique()))

"""이 데이터에는 47,959개의 문장이 있으며 문장들은 35,178개의 단어를 가지고 17개 종류의 개체명 태깅을 가집니다. 

17개의 개체명 태깅이 전체 데이터에서 몇 개가 있는지, 개체명 태깅 개수의 분포를 확인해보도록 하겠습니다.
"""

print('Tag 열의 각각의 값의 개수 카운트')
print('================================')
print(data.groupby('Tag').size().reset_index(name='count'))

"""BIO 표현 방법에서 아무런 태깅도 의미하지 않는 "O"가 가장 887,908개로 가장 많은 개수를 차지함을 볼 수 있습니다. 

데이터를 원하는 형태로 가공해보겠습니다. 우선 Null 값을 제거합니다. Pandas의 `fillna(method='ffill')`는 Null 값을 가진 행의 바로 앞의 행의 값으로 Null 값을 채우는 작업을 수행합니다. t번째 문장에 속하면서 Null 값을 가진 샘플들은 전부 첫번째 열에 Sentence: t의 값이 들어갑니다. 

이번에는 뒤의 5개의 샘플을 출력해서 정상적으로 수행되었는지 확인해봅시다.
"""

data = data.fillna(method="ffill")
print(data.tail())

"""뒤의 5개 샘플의 첫번째 열이 Sentence: 47959로 채워졌습니다. 이는 47,959번째 문장임을 의미하며, Null 값을 가진 행들의 바로 앞 행의 Sentence # 열의 값이 Sentence: 47959이었음을 의미합니다. 전체 데이터에 Null 값이 존재하는지 확인해봅시다."""

print('데이터에 Null 값이 있는지 유무 : ' + str(data.isnull().values.any()))

"""없는 것으로 나옵니다. 모든 단어를 소문자화하여 단어의 개수를 줄여보겠습니다."""

data['Word'] = data['Word'].str.lower()
print('Word 열의 중복을 제거한 값의 개수 : {}'.format(data.Word.nunique()))

"""정상적으로 소문자화가 되었는지 앞의 샘플 5개만 출력해보겠습니다."""

print(data[:5])

"""하나의 문장에 등장한 단어와 개체명 태깅 정보끼리 쌍(pair)으로 묶는 작업을 수행합니다."""

func = lambda temp: [(w, t) for w, t in zip(temp["Word"].values.tolist(), temp["Tag"].values.tolist())]
tagged_sentences=[t for t in data.groupby("Sentence #").apply(func)]
print("전체 샘플 개수: {}".format(len(tagged_sentences)))

"""1,000,616개의 행의 개수가 각 문장당 하나의 샘플로 묶이면서 47,959개의 샘플이 되었습니다. 정상적으로 수행되었는지 첫번째 샘플을 출력해봅시다."""

print(tagged_sentences[0]) # 첫번째 샘플 출력

"""전처리가 수행된 첫번째 샘플이 출력됩니다. 이러한 샘플이 총 47,959개가 있습니다. 

그런데 훈련을 시키려면 훈련 데이터에서 단어에 해당되는 부분과 개체명 태깅 정보에 해당되는 부분을 분리시켜야 합니다. 즉, [('thousands', 'O'), ('of', 'O')]와 같은 문장 샘플이 있다면 thousands와 of는 같이 저장하고, O와 O를 같이 저장할 필요가 있습니다. 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 하는 `zip()`을 사용하여 단어와 개체명 태깅 정보를 분리해봅시다.
"""

sentences, ner_tags = [], [] 
for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.

    # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.
    sentence, tag_info = zip(*tagged_sentence) 
    sentences.append(list(sentence)) # 각 샘플에서 단어 정보만 저장한다.
    ner_tags.append(list(tag_info)) # 각 샘플에서 개체명 태깅 정보만 저장한다

"""각 문장 샘플에서 단어는 `sentences`에, 태깅 정보는 `ner_tags`에 저장하였습니다. 임의로 첫번째 문장 샘플을 출력해보겠습니다."""

print(sentences[0])
print(ner_tags[0])

"""첫번째 샘플에 대해서 단어에 대해서만 `sentences[0]`에, 또한 개체명에 대해서만 `ner_tags[0]`에 저장된 것을 볼 수 있습니다. 

뒤에서 보겠지만, `sentences`는 예측을 위한 `X`에 해당되며 `ner_tags`는 예측 대상인 `y`에 해당됩니다. 다른 샘플들에 대해서도 처리가 되었는지 확인하기 위해 임의로 98번 인덱스의 샘플에 대해서도 확인해보겠습니다.
"""

print(sentences[98])
print(ner_tags[98])

"""단어에 대해서만 `sentences[98]`에, 또한 개체명에 대해서만 `ner_tags[98]`에 저장된 것을 확인할 수 있습니다. 

또한 첫번째 샘플과 길이가 다릅니다. 47,959개의 문장 샘플의 길이는 서로 다를 수 있습니다. 전체 데이터의 길이 분포를 확인해봅시다.
"""

print('샘플의 최대 길이 : %d' % max(len(l) for l in sentences))
print('샘플의 평균 길이 : %f' % (sum(map(len, sentences))/len(sentences)))
plt.hist([len(s) for s in sentences], bins=50)
plt.xlabel('length of samples')
plt.ylabel('number of samples')
plt.show()

"""위의 그래프는 샘플들의 길이가 대체적으로 0~40의 길이를 가지는 것을 보여줍니다. 길이가 가장 긴 샘플의 길이는 104입니다. 케라스 토크나이저를 통해서 정수 인코딩을 진행합니다. 이번에는 문장 데이터에 있는 모든 단어를 사용하겠습니다.


"""

# 모든 단어를 사용하며 인덱스 1에는 단어 'OOV'를 할당.
src_tokenizer = Tokenizer(oov_token='OOV')
# 태깅 정보들은 내부적으로 대문자를 유지한 채 저장
tar_tokenizer = Tokenizer(lower=False)

src_tokenizer.fit_on_texts(sentences)
tar_tokenizer.fit_on_texts(ner_tags)

"""문장 데이터에 대해서는 `src_tokenizer`를, 레이블에 해당되는 개체명 태깅 정보에 대해서는 `tar_tokenizer`를 사용합니다."""

vocab_size = len(src_tokenizer.word_index) + 1
tag_size = len(tar_tokenizer.word_index) + 1
print('단어 집합의 크기 : {}'.format(vocab_size))
print('개체명 태깅 정보 집합의 크기 : {}'.format(tag_size))

"""앞서 `src_tokenizer`를 만들때 Tokenizer의 인자로 `oov_token='OOV'`를 선택했습니다. 인덱스1에 단어 'OOV'가 할당됩니다."""

print('단어 OOV의 인덱스 : {}'.format(src_tokenizer.word_index['OOV']))

"""정수 인코딩을 수행합니다."""

X_data = src_tokenizer.texts_to_sequences(sentences)
y_data = tar_tokenizer.texts_to_sequences(ner_tags)

"""문장 데이터에 대해서 정수 인코딩이 수행된 결과는 `X_data`, 개체명 태깅 데이터에 대해서 정수 인코딩이 수행된 결과는 `y_data`에 저장되었습니다. 정수 인코딩이 되었는지 확인을 위해 임의로 첫번째 샘플을 출력해보겠습니다."""

print(X_data[0])
print(y_data[0])

"""모델 훈련 후 결과 확인을 위해 인덱스로부터 단어를 리턴하는 `index_to_word`와 인덱스로부터 개체명 태깅 정보를 리턴하는 `index_to_ner`를 만듭니다. 인덱스 0은 'PAD'란 단어를 할당해둡니다. `index_to_ner`은 개수가 적으니 출력해봅시다."""

word_to_index = src_tokenizer.word_index
index_to_word = src_tokenizer.index_word
ner_to_index = tar_tokenizer.word_index
index_to_ner = tar_tokenizer.index_word
index_to_ner[0] = 'PAD'

print(index_to_ner)

"""`index_to_word`를 통해 첫번째 샘플의 정수 시퀀스를 텍스트 시퀀스로 변환하는 디코딩 작업을 해보겠습니다."""

decoded = []
for index in X_data[0] : # 첫번째 샘플 안의 인덱스들에 대해서
    decoded.append(index_to_word[index]) # 다시 단어로 변환

print('기존의 문장 : {}'.format(sentences[0]))
print('디코딩 문장 : {}'.format(decoded))

"""`X` 데이터와 `y` 데이터가 구성되었습니다. 패딩 작업을 진행해봅시다. 앞서 확인하였듯이 대부분의 데이터의 길이는 40~60에 분포되어져 있습니다. 그러므로 가장 긴 샘플의 길이인 104가 아니라 70정도로 `max_len`을 정해보겠습니다."""

max_len = 70
X_data = pad_sequences(X_data, padding='post', maxlen=max_len)
y_data = pad_sequences(y_data, padding='post', maxlen=max_len)

"""모든 샘플의 길이가 70이 되었습니다. 훈련 데이터와 테스트 데이터를 8:2의 비율로 분리합니다."""

X_train, X_test, y_train_int, y_test_int = train_test_split(X_data, y_data, test_size=.2, random_state=777)

"""레이블에 해당하는 태깅 정보에 대해서 원-핫 인코딩을 수행합니다.

"""

y_train = to_categorical(y_train_int, num_classes=tag_size)
y_test = to_categorical(y_test_int, num_classes=tag_size)

"""각 데이터 크기를 확인해보겠습니다.

"""

print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))
print('훈련 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_train_int.shape))
print('훈련 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_train.shape))
print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))
print('테스트 샘플 레이블(정수 인코딩)의 크기 : {}'.format(y_test_int.shape))
print('테스트 샘플 레이블(원-핫 인코딩)의 크기 : {}'.format(y_test.shape))

"""## 2. 양방향 LSTM을 이용한 개체명 인식

하이퍼파라미터인 임베딩 벡터의 차원은 128, 은닉 상태의 크기는 256입니다. 모델은 다 대 다 구조의 양방향 LSTM을 사용합니다. 이 경우 LSTM의 `return_sequences`의 인자값은 `True`로 주어야만 합니다. 이번 실습과 같이 각 데이터의 길이가 달라서 패딩을 하느라 숫자 0이 많아질 경우에는 Embedding()에 `mask_zero=True`를 설정하여 숫자 0은 연산에서 제외시킨다는 옵션을 줄 수 있습니다. 출력층에 `TimeDistributed()`를 사용했는데, `TimeDistributed()`는 LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용할 필요가 있을 때 사용합니다.

해당 모델은 모든 시점에 대해서 개체명 레이블 개수만큼의 선택지 중 하나를 예측하는 다중 클래스 분류 문제를 수행하는 모델입니다. 다중 클래스 분류 문제의 경우, 출력층에 소프트맥스 회귀를 사용해야 하므로 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로 크로스 엔트로피 함수를 사용합니다. 하이퍼파라미터인 배치 크기는 128이며, 6 에포크를 수행합니다. `validation_split=0.1`을 사용하여 훈련 데이터의 10%를 검증 데이터로 분리해서 사용하고, 검증 데이터를 통해서 훈련이 적절히 되고 있는지 확인합니다. 검증 데이터는 기계가 훈련 데이터에 과적합되고 있지는 않은지 확인하기 위한 용도로 사용됩니다.
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding
from tensorflow.keras.optimizers import Adam
import numpy as np

embedding_dim = 128
hidden_units = 256

model = Sequential()
model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))
model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))
model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))
model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])

history = model.fit(X_train, y_train, batch_size=128, epochs=6, validation_split=0.1)

print("\n 테스트 정확도: %.4f" % (model.evaluate(X_test, y_test)[1]))

"""검증 데이터와 테스트 데이터에 대해서 약 95%의 정확도를 얻습니다. 테스트 데이터의 임의의 인덱스 13번 샘플에 대해서 실제값과 예측값을 비교해봅시다."""

i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.
y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴
y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 인코딩으로 변경함.
labels = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.

print("{:15}|{:5}|{}".format("단어", "실제값", "예측값"))
print(35 * "-")

for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):
    if word != 0: # PAD값은 제외함.
        print("{:17}: {:7} {}".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))

"""정확하게 예측했습니다. F1-score라는 성능 평가 방법에 대해서 이해하고, 테스트 데이터에 대해서 성능을 측정해봅시다.

## 3. F1-score로 성능 측정하기

개체명 인식에서는 그 어떤 개체도 아니라는 의미의 'O'라는 태깅이 존재합니다. 그런데 이런 정보는 보통 대다수의 레이블을 차지하기 때문에 기존에 사용했던 정확도(accuracy)를 평가 방법으로 사용하는 것이 적절하지 않을 수 있습니다.

파이썬 패키지 `seqeval`를 설치합니다.
"""

!pip install seqeval

"""개체명 인식 모델의 성능 측정을 위해 정밀도와 재현률 개념을 사용해보겠습니다. 이를 개체명 인식 문제에 맞도록 해석해보면 다음과 같습니다.

$$\text{정밀도} = \frac{TP}{TP + FP} = \text{특정 개체라고 예측한 경우 중에서 실제 특정 개체로 판명되어 예측이 일치한 비율}$$

$$\text{재현률} = \frac{TP}{TP + FN} = \text{전체 특정 개체 중에서 실제 특정 개체라고 정답을 맞춘 비율}$$

정밀도와 재현률로부터 조화 평균(harmonic mean)을 구한 것을 f1-score라고 합니다.

$$f1\ score = 2 × \frac{\text{정밀도 × 재현률}}{\text{정밀도 + 재현률}}$$

predicted의 성능을 평가하기 위해서 정밀도, 재현률, f1-score를 계산해보도록 하겠습니다.
"""

from seqeval.metrics import f1_score, classification_report

"""F1-score를 계산하기 위해서 개체명 태깅의 확률 벡터 또는 원-핫 벡터로부터 태깅 정보 시퀀스로 변환하는 함수인 `sequences_to_tag`를 만듭니다. 해당 함수를 통해 모델의 예측값인 `y_predicted`와 실제값에 해당하는 `y_test`를 태깅 정보 시퀀스로 변환합니다. 그리고 두 개를 비교하여 f1-score를 계산합니다."""

def sequences_to_tag(sequences):
    result = []
    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.
    for sequence in sequences:
        word_sequence = []
        # 시퀀스로부터 확률 벡터 또는 원-핫 벡터를 하나씩 꺼낸다.
        for pred in sequence:
            # 정수로 변환. 예를 들어 pred가 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.
            pred_index = np.argmax(pred)            
            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.
            word_sequence.append(index_to_ner[pred_index].replace("PAD", "O"))
        result.append(word_sequence)
    return result

y_predicted = model.predict([X_test])
pred_tags = sequences_to_tag(y_predicted)
test_tags = sequences_to_tag(y_test)

print("F1-score: {:.1%}".format(f1_score(test_tags, pred_tags)))
print(classification_report(test_tags, pred_tags))

"""이어서 CRF 층을 추가하여 성능을 높여봅시다.

# BiLSTM-CRF를 이용한 개체명 인식

이번에는 기존의 양방향 LSTM 모델에 CRF(Conditional Random Field)라는 새로운 층을 추가하여 보다 모델을 개선시킨 양방향 LSTM + CRF 모델을 사용하여 개체명 인식(Named Entity Recognition)을 수행합니다.

논문 링크 : https://arxiv.org/pdf/1508.01991v1.pdf<br>
논문 링크 : https://arxiv.org/pdf/1603.01360.pdf

## 1. CRF(Conditional Random Field)

CRF는 Conditional Random Field의 약자로 양방향 LSTM을 위해 탄생한 모델이 아니라 이전에 독자적으로 존재해왔던 모델입니다. 이를 양방향 LSTM 모델 위에 하나의 층으로 추가하여, 양방향 LSTM + CRF 모델이 탄생하였습니다. 여기서는 CRF의 수식적 이해가 아니라 양방향 LSTM + CRF 모델의 직관에 대해서 이해합니다.

CRF 층의 역할을 이해하기 위해서 간단한 개체명 인식 작업의 예를 들어보겠습니다. 사람(Person), 조직(Organization) 두 가지만을 태깅하는 간단한 태깅 작업에 BIO 표현을 사용한다면 여기서 사용하는 태깅의 종류는 아래의 5가지입니다.

```
B-Per, I-Per, B-Org, I-Org, O
```

아래의 그림은 위의 태깅을 수행하는 기존의 양방향 LSTM 개체명 인식 모델의 예를 보여줍니다.

![](https://wikidocs.net/images/page/34156/bilstmcrf1.PNG)

위 모델은 각 단어를 벡터로 입력받고, 모델의 출력층에서 활성화 함수를 통해 개체명을 예측합니다. 사실 입력 단어들과 실제 개체명이 무엇인지 모르는 상황이므로 이 모델이 정확하게 개체명을 예측했는지는 위 그림만으로는 알 수 없습니다. 또 다른 예를 보겠습니다.

![](https://wikidocs.net/images/page/34156/bilstmcrf2_%EC%88%98%EC%A0%95.PNG)

위 모델은 명확히 틀린 예측을 포함하고 있습니다. 입력 단어들과 실제값의 여부와 상관없이 이 사실을 알 수 있습니다. BIO 표현에 따르면 우선, 첫번째 단어의 레이블에서 I가 등장할 수 없습니다. 또한 I-Per은 반드시 B-Per 뒤에서만 등장할 수 있습니다. 뿐만 아니라, I-Org도 마찬가지로 B-Org 뒤에서만 등장할 수 있는데 위 모델은 이런 BIO 표현 방법의 제약사항들을 모두 위반하고 있습니다.

여기서 양방향 LSTM 위에 CRF 층을 추가하여 얻을 수 있는 이점을 언급하겠습니다. CRF 층을 추가하면 모델은 예측 개체명, 다시 말해 레이블 사이의 의존성을 고려할 수 있습니다. 아래의 그림은 양방향 LSTM + CRF 모델을 보여줍니다.

![](https://wikidocs.net/images/page/34156/bilstmcrf3.PNG)

앞서봤듯이, 기존에 CRF 층이 존재하지 않았던 양방향 LSTM 모델은 활성화 함수를 지난 시점에서 개체명을 결정했지만, CRF 층을 추가한 모델에서는 활성화 함수의 결과들이 CRF 층의 입력으로 전달됩니다. 예를 들어 `word1`에 대한 양방향 LSTM 셀과 활성화 함수를 지난 출력값 [0.7, 0.12, 0.08, 0.04, 0.06]은 CRF 층의 입력이 됩니다. 마찬가지로 모든 단어에 대한 활성화 함수를 지난 출력값은 CRF 층의 입력이 되고, CRF 층은 레이블 시퀀스에 대해서 가장 높은 점수를 가지는 시퀀스를 예측합니다.

이러한 구조에서 CRF 층은 점차적으로 훈련 데이터로부터 아래와 같은 제약사항 등을 학습하게 됩니다.

1. 문장의 첫번째 단어에서는 I가 나오지 않습니다.
2. O-I 패턴은 나오지 않습니다.
3. B-I-I 패턴에서 개체명은 일관성을 유지합니다. 예를 들어 B-Per 다음에 I-Org는 나오지 않습니다.

요약하면 양방향 LSTM은 입력 단어에 대한 양방향 문맥을 반영하며, CRF는 출력 레이블에 대한 양방향 문맥을 반영합니다.

## 2. CRF 층 설치하기

CRF 층을 손쉽게 사용하기 위한 `keras-crf`를 설치합니다.

깃허브 링크 : https://github.com/luozhouyang/keras-crf
"""

!pip install keras-crf

"""## 3. BiLSTM-CRF를 이용한 개체명 인식

이전과 동일한 데이터에 대해서 모델을 학습해봅시다. 마지막 층에 CRF 층을 추가하기 위하여 함수형 API를 사용합니다. 하이퍼파라미터인 임베딩 벡터의 차원은 128, 은닉 상태의 크기는 64입니다. 모델은 다 대 다 구조의 양방향 LSTM을 사용합니다. 이 경우 LSTM의 `return_sequences`의 인자값은 `True`로 주어야만 합니다. 출력층에 `TimeDistributed()`를 사용했는데, `TimeDistributed()`는 LSTM을 다 대 다 구조로 사용하여 LSTM의 모든 시점에 대해서 출력층을 사용할 필요가 있을 때 사용합니다.

해당 모델은 모든 시점에 대해서 개체명 레이블 개수만큼의 선택지 중 하나를 예측하는 다중 클래스 분류 문제를 수행하는 모델입니다. 여기서는 최종 출력층이 CRF 층으로 CRF 층에 분류해야 하는 선택지 개수를 의미하는 `tag_size`를 전달해줍니다.
"""

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, LSTM, Input, Bidirectional, TimeDistributed, Embedding, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from keras_crf import CRFModel
from seqeval.metrics import f1_score, classification_report

embedding_dim = 128
hidden_units = 64
dropout_ratio = 0.3

sequence_input = Input(shape=(max_len,),dtype=tf.int32, name='sequence_input')

model_embedding = Embedding(input_dim=vocab_size,
                            output_dim=embedding_dim,
                            input_length=max_len)(sequence_input)

model_bilstm = Bidirectional(LSTM(units=hidden_units, return_sequences=True))(model_embedding)

model_dropout = TimeDistributed(Dropout(dropout_ratio))(model_bilstm)

model_dense = TimeDistributed(Dense(tag_size, activation='relu'))(model_dropout)

base = Model(inputs=sequence_input, outputs=model_dense)
model = CRFModel(base, tag_size)
model.compile(optimizer=tf.keras.optimizers.Adam(0.001), metrics='accuracy')

"""하이퍼파라미터인 배치 크기는 128이며, 15 에포크를 수행합니다. `validation_split=0.1`을 사용하여 훈련 데이터의 10%를 검증 데이터로 분리해서 사용하고, 검증 데이터를 통해서 훈련이 적절히 되고 있는지 확인합니다. 검증 데이터는 기계가 훈련 데이터에 과적합되고 있지는 않은지 확인하기 위한 용도로 사용됩니다. 조기 종료를 사용하기 위해서 콜백을 정의합니다. `keras-crf`가 원-핫 인코딩 된 레이블은 지원하지 않으므로 `y_train`이 아니라 `y_train_int`를 사용함을 주의합니다."""

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
mc = ModelCheckpoint('bilstm_crf/cp.ckpt', monitor='val_decode_sequence_accuracy', mode='max', verbose=1, save_best_only=True, save_weights_only=True)

history = model.fit(X_train, y_train_int, batch_size=128, epochs=15, validation_split=0.1, callbacks=[mc, es])

"""조기 종료로 학습이 끝났다면 검증 데이터에 대해서 정확도가 가장 높았을 당시를 저장해둔 가중치를 불러온 후, 임의로 선정한 테스트 데이터의 13번 인덱스의 샘플에 대해서 예측해봅시다.

"""

model.load_weights('bilstm_crf/cp.ckpt')

i = 13 # 확인하고 싶은 테스트용 샘플의 인덱스.
y_predicted = model.predict(np.array([X_test[i]]))[0] # 입력한 테스트용 샘플에 대해서 예측 y를 리턴
labels = np.argmax(y_test[i], -1) # 원-핫 인코딩을 다시 정수 인코딩으로 변경.

print("{:15}|{:5}|{}".format("단어", "실제값", "예측값"))
print(35 * "-")

for word, tag, pred in zip(X_test[i], labels, y_predicted[0]):
    if word != 0: # PAD값은 제외함.
        print("{:17}: {:7} {}".format(index_to_word[word], index_to_ner[tag], index_to_ner[pred]))

"""정확하게 잘 예측한 것 같습니다. 테스트 데이터에 대해서 성능을 측정해봅시다. 테스트 데이터에 대한 예측 시퀀스인 y_predicted를 얻습니다."""

y_predicted = model.predict(X_test)[0]

"""상위 2개만 출력해봅시다.

"""

print(y_predicted[:2])

"""예측값으로 확률 벡터가 아니라 정수 시퀀스가 출력됩니다. 이 경우 이전 실습에서 사용했던 함수인 `sequences_to_tag`를 사용할 수 없으므로 함수를 수정해야 합니다. 확률 벡터가 아닌 정수 시퀀스를 입력으로 받아서 태깅 정보 시퀀스를 리턴하는 함수로 `sequences_to_tag_for_crf`를 만듭니다. 해당 함수를 사용하여 예측값과 레이블에 해당하는 `y_test`를 태깅 정보 시퀀스로 변환하여 F1-score를 계산합니다.

"""

def sequences_to_tag_for_crf(sequences): 
    result = []
    # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.
    for sequence in sequences: 
        word_sequence = []
        # 시퀀스로부터 예측 정수 레이블을 하나씩 꺼낸다.
        for pred_index in sequence:
            # index_to_ner을 사용하여 정수를 태깅 정보로 변환. 'PAD'는 'O'로 변경.
            word_sequence.append(index_to_ner[pred_index].replace("PAD", "O"))
        result.append(word_sequence)
    return result

pred_tags = sequences_to_tag_for_crf(y_predicted)
test_tags = sequences_to_tag(y_test)

print("F1-score: {:.1%}".format(f1_score(test_tags, pred_tags)))
print(classification_report(test_tags, pred_tags))

